---
editor_options: 
  markdown: 
    wrap: 72
---

# Clustering and classification

*Describe the work you have done this week and summarize your learning.*

-   Describe your work and results clearly.
-   Assume the reader has an introductory course level understanding of
    writing and reading R code as well as statistical methods.
-   Assume the reader has no previous knowledge of your data or the more
    advanced methods you are using.

```{r}
date()

# load libraries
library(ggplot2)
library(GGally)
library(dplyr)
library(corrplot)
library(MASS)
library(tidyr)
```

### Description of the data

```{r}
# load the Boston data
data("Boston")
# explore the structure and dimensions of the data
str(Boston)
dim(Boston)
```

The dataset contains information about housing in Boston, costisting of
506 observations and 14 variables, with the following information:

-   **crim**: Per capita crime rate by town.
-   **zn**: Proportion of residential land zoned for lots over 25,000
    sq. ft.
-   **indus**: Proportion of non-retail business acres per town.
-   **chas**: Charles River dummy variable (1 if tract bounds river; 0
    otherwise).
-   **nox**: Nitric oxides concentration (parts per 10 million).
-   **rm**: Average number of rooms per dwelling.
-   **age**: Proportion of owner-occupied units built prior to 1940.
-   **dis**: Weighted distances to five Boston employment centers.
-   **rad**: Index of accessibility to radial highways.
-   **tax**: Full-value property tax rate per \$10,000.
-   **ptratio**: Pupil-teacher ratio by town.
-   **black**: 1000(Bkâˆ’0.63) 2 where Bk is the proportion of Black
    residents by town
-   **lstat**: Percentage of lower status of the population.
-   **medv**: Median value of owner-occupied homes in \$1000s.




### Variable visualization

```{r}
# generate variable pairs
ggpairs(Boston, lower = list(combo = wrap("facethist", bins = 20)))
# generate correlation plots
corrplot(cor(Boston) %>% round(2), method="circle", type = "upper")
```

From the plots, I can appreciate that many variables are correlated. For instance,
**indus** and **nox** both positively and negatively correlate with most of the
other variables.



### Standardise and split the data

```{r}
# center and standardize variables
boston_scaled <- as.data.frame(scale(Boston))
# summaries of the scaled variables
summary(boston_scaled)
```

The applied scaling subtract the column means is substracted from the corresponding
columns and the resulting difference is divided with standard deviation.


```{r}
# create a quantile vector of crim 
bins <- quantile(boston_scaled$crim)
# create a categorical variable 'crime'
crime <- cut(boston_scaled$crim, breaks = bins, include.lowest = TRUE,
             labels = c("low", "med_low", "med_high", "high"))
# remove original crim from the dataset
boston_scaled <- dplyr::select(boston_scaled, -crim)
# add the new categorical value to scaled data
boston_scaled <- data.frame(boston_scaled, crime)



# split the dataset into train and test
n <- nrow(boston_scaled)
# choose randomly 80% of the rows
ind <- sample(n,  size = n * 0.8)
# create train set
train <- boston_scaled[ind,]
# create test set 
test <- boston_scaled[-ind,]
```



### Linear discriminant analysis
```{r}
# linear discriminant analysis
lda.fit <- lda(crime ~ ., data = train)
# the function for lda biplot arrows
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "red", tex = 0.75, choices = c(1,2)){
  heads <- coef(x)
  graphics::arrows(x0 = 0, y0 = 0, 
         x1 = myscale * heads[,choices[1]], 
         y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
  text(myscale * heads[,choices], labels = row.names(heads), 
       cex = tex, col=color, pos=3)
}
# numeric vector of crime classes
classes <- as.numeric(train$crime)
# plot the lda results (select both lines and execute them at the same time!)
plot(lda.fit, col = classes, pch = classes, dimen = 2)
lda.arrows(lda.fit, myscale = 1)

```



### Cross tabulation
```{r}
# crime categories from test set
correct_classes <- test$crime
# remove the crime variable from test set
test <- dplyr::select(test, -crime)
# predict classes with test data
lda.pred <- predict(lda.fit, newdata = test)
# cross tabulate the results
table(correct = correct_classes, predicted = lda.pred$class)
```

The cross tabulation shows that the LDA is very good at predicting the *high*
category and quite good at discriminating the *med_high* one. When it comes to
*low* and *med_low* categories, the model is working worse with many mis-classified
events.



### Clustering
```{r}
set.seed(007)
# re-load, center and standardize the Boston dataset
boston_scaled <- as.data.frame(scale(Boston))
# calculate the distance
dist_eu <- dist(boston_scaled)
#run k-means
km <- kmeans(boston_scaled, centers = 4)
pairs(boston_scaled, col = km$cluster)

# determine the number of clusters
k_max <- 10
# calculate the total within sum of squares
twcss <- sapply(1:k_max, function(k){kmeans(boston_scaled, k)$tot.withinss})
# visualize the results
qplot(x = 1:k_max, y = twcss, geom = 'line')
```

The optimal number of clusters seems to be three.


```{r}
# re-run clustering
km <- kmeans(boston_scaled, centers = 3)
pairs(boston_scaled, col = km$cluster)
```

Three looks to be a much better number of clusters compared to four.



### LDA to predict clustering classes
```{r}
set.seed(007)
# re-load, center and standardize the Boston dataset
boston_scaled <- as.data.frame(scale(Boston))
# re-run clustering
km <- kmeans(boston_scaled, centers = 3)
boston_scaled$km_clusters <- km$cluster

# linear discriminant analysis
lda.fit <- lda(km_clusters ~ ., data = boston_scaled)
# the function for lda biplot arrows
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "red", tex = 0.75, choices = c(1,2)){
  heads <- coef(x)
  graphics::arrows(x0 = 0, y0 = 0, 
         x1 = myscale * heads[,choices[1]], 
         y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
  text(myscale * heads[,choices], labels = row.names(heads), 
       cex = tex, col=color, pos=3)
}
# numeric vector of crime classes
classes <- as.numeric(boston_scaled$km_clusters)
# plot the lda results (select both lines and execute them at the same time!)
plot(lda.fit, col = classes, pch = classes, dimen = 2)
lda.arrows(lda.fit, myscale = 1)

```